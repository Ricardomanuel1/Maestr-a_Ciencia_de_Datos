{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardomanuel1/Maestria_Ciencia_de_Datos/blob/main/MACHINE%20LEARNING%20Y%20DEEP%20LEARNING/cnns_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset\n",
        "\n",
        "La base de datos MNIST (Modified National Institute of Standards and Technology) es un conjunto de datos ampliamente utilizado en la comunidad de aprendizaje automático para entrenar y probar modelos de clasificación de imágenes. Contiene imágenes de dígitos escritos a mano del 0 al 9, y es especialmente útil para trabajar con técnicas de procesamiento de imágenes y redes neuronales.\n",
        "\n",
        "Características de la Base de Datos MNIST:\n",
        "\n",
        "* **Número de Imágenes**: 70,000 imágenes en total.\n",
        "* **Conjunto de Entrenamiento**: 60,000 imágenes.\n",
        "* **Conjunto de Prueba**: 10,000 imágenes.\n",
        "* **Dimensiones de las Imágenes**: Cada imagen es de 28x28 píxeles.\n",
        "* **Formato de las Imágenes**: Escala de grises (un solo canal).\n",
        "* **Etiquetas**: Cada imagen está etiquetada con el dígito correspondiente (0-9).\n",
        "\n",
        "Estructura de las Imágenes:\n",
        "\n",
        "* Pixeles: Los valores de los píxeles varían de 0 a 255.\n",
        "* 0: Representa un píxel negro (fondo).\n",
        "* 255: Representa un píxel blancos (trazo del dígito)."
      ],
      "metadata": {
        "id": "gW17l4-bJvLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de la Base de Datos MNIST\n",
        "\n",
        "PyTorch proporciona herramientas dentro de torchvision para cargar y preprocesar la base de datos MNIST fácilmente."
      ],
      "metadata": {
        "id": "7gOeWRnB24fB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mqqDRXRHnv0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Podemos aplicar transformaciones a nuestros datos"
      ],
      "metadata": {
        "id": "_hSTDNPuLCHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = T.Compose([\n",
        "            T.RandomCrop(32, padding=4),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.ToTensor()])\n",
        "\n",
        "valid_transform = T.Compose([\n",
        "            T.RandomCrop(32, padding=4),\n",
        "            T.ToTensor()])"
      ],
      "metadata": {
        "id": "T4mLcdO7LKRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = train_transform,\n",
        "    download = True)"
      ],
      "metadata": {
        "id": "GuXtl6f2Hz1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = valid_transform,\n",
        "    download = True)"
      ],
      "metadata": {
        "id": "Kax0DvNCLar7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = valid_transform)"
      ],
      "metadata": {
        "id": "fNU1x6sMH65z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train size: {}\".format(len(train_data)))\n",
        "print(\"test size : {}\".format(len(test_data)))"
      ],
      "metadata": {
        "id": "Vm8V55khH981"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader\n",
        "\n",
        "El DataLoader en PyTorch es una herramienta fundamental para la preparación y el suministro de datos a modelos de aprendizaje automático. Facilita la carga, el procesamiento y la iteración eficiente de grandes conjuntos de datos durante el entrenamiento y la evaluación de modelos. Utiliza múltiples subprocesos para cargar datos en paralelo, acelerando la preparación de los datos y reduciendo los tiempos de espera durante el entrenamiento\n"
      ],
      "metadata": {
        "id": "DWvm7AogJ-nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "cfCTtn7KJTrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Svt22oOeSjTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separa los datos que no son del **test** en dos partes\n",
        "\n",
        "* Datos de entrenamiento\n",
        "* Datos de validación"
      ],
      "metadata": {
        "id": "WquNApcRJOIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "def split_train_valid_data(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    valid_size=0.1,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    random_seed=0,\n",
        "    num_workers=4):\n",
        "\n",
        "  num_train = len(train_data)\n",
        "  indices = list(range(num_train))\n",
        "  split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "  if shuffle == True:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "  train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "  train_sampler = SubsetRandomSampler(train_idx)\n",
        "  valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                    batch_size=batch_size, sampler=train_sampler,\n",
        "                    num_workers=num_workers)\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                    batch_size=batch_size, sampler=valid_sampler,\n",
        "                    num_workers=num_workers)\n",
        "\n",
        "  return (train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "0SYcdhsXJNi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualización\n",
        "\n",
        "Podemos utilizar la librería **matplotlib** para visualizar las imágenes de la base de datos MNIST"
      ],
      "metadata": {
        "id": "N7Pf2qV4J5VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4Z0HXBe8Irne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_data.data[0], cmap='gray')\n",
        "plt.title('%i' % train_data.targets[0])\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1sDRNlWwI8M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 9))\n",
        "cols, rows = 5, 5\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2z-QGO7TI96t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo LeNet-5\n",
        "LeNet-5 es uno de los primeros modelos de redes neuronales convolucionales (CNNs) y fue desarrollado por científicos---entre ellos Yann LeCun---en 1998. Este modelo se diseñó principalmente para reconocer dígitos escritos a mano y fue utilizado para la lectura automatizada de cheques y documentos. LeNet-5 sentó las bases para el desarrollo de CNNs más avanzadas y modernas, influyendo significativamente en el campo del reconocimiento de patrones y el aprendizaje profundo."
      ],
      "metadata": {
        "id": "Uoyx9_zxKEpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Arquitectura del Modelo LeNet-5\n",
        "\n",
        "LeNet-5 tiene una arquitectura sencilla y bien estructurada, que consta de 7 capas (excluyendo las capas de entrada y salida). Estas capas incluyen tres capas convolucionales, dos capas de subsampling (o pooling), y dos capas completamente conectadas.\n",
        "\n",
        "### 1.1. Capa de Entrada:\n",
        "\n",
        "* Dimensión: 32x32 píxeles (imagen en escala de grises).\n",
        "* Nota: Las imágenes de MNIST originalmente son de 28x28 píxeles, por lo que se * agregan bordes para aumentar a 32x32 píxeles.\n",
        "\n",
        "### 1.2. Capa Convolucional **conv1**:\n",
        "\n",
        "* Filtros: 6 filtros de 5x5.\n",
        "* Salida: 6 mapas de características de 28x28 (32 - 5 + 1 = 28).\n",
        "\n",
        "### 1.3. Capa de Subsampling **s1**:\n",
        "\n",
        "* Operación: Subsampling (promedio) con una ventana de 2x2.\n",
        "* Salida: 6 mapas de características de 14x14.\n",
        "\n",
        "### 1.4. Capa Convolucional **conv2**:\n",
        "\n",
        "* Filtros: 16 filtros de 5x5.\n",
        "* Salida: 16 mapas de características de 10x10 (14 - 5 + 1 = 10).\n",
        "\n",
        "### 1.5. Capa de Subsampling **s2**:\n",
        "\n",
        "* Operación: Subsampling (promedio) con una ventana de 2x2.\n",
        "* Salida: 16 mapas de características de 5x5.\n",
        "\n",
        "### 1.6. Capa Convolucional **conv3**:\n",
        "\n",
        "Filtros: 120 filtros de 5x5.\n",
        "Salida: 120 mapas de características de 1x1 (5 - 5 + 1 = 1).\n",
        "\n",
        "### 1.7. Capa Completamente Conectada **f1**:\n",
        "\n",
        "* Neuronas: 84.\n",
        "* Operación: Función de activación sigmoid o tanh.\n",
        "\n",
        "### 1.8 Capa Completamente Conectada **f2** (salida):\n",
        "\n",
        "* Neuronal: 10 (una por cada dígito del 0 al 9).\n",
        "* Operación: Función de activación **softmax** para clasificación.\n",
        "\n",
        "### 1.2. Flujo de Datos en la Red\n",
        "* Entrada: Imagen de 32x32 píxeles.\n",
        "* **conv1**: Convolución → 28x28x6.\n",
        "* **s2**: Subsampling → 14x14x6.\n",
        "* **conv2**: Convolución → 10x10x16.\n",
        "* **s2**: Subsampling → 5x5x16.\n",
        "* **conv3**: Convolución → 1x1x120.\n",
        "* **f1**: Conexión completa → 84.\n",
        "* **f2**: Conexión completa → 10 (clases)."
      ],
      "metadata": {
        "id": "nqpUkFyN49Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        # conv1: entrada 1 canal, salida 6 canales, tamaño de kernel 5x5\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "\n",
        "        # conv1: entrada 6 canales, salida 16 canales, tamaño de kernel 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # conv3: entrada 16*4*4, salida 120\n",
        "        self.conv3 = nn.Conv2d(16, 120, 5)\n",
        "\n",
        "        # f2: entrada 120, salida 84\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        # Capa completamente conectada 3: entrada 84, salida 10 (dígitos)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Aplicar la primera capa convolucional seguida de ReLU y max pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "\n",
        "        # Aplicar la segunda capa convolucional seguida de ReLU y max pooling\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "\n",
        "        # Aplicar la tercera capa convolucional seguida de ReLU\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Aplanar los datos para la capa completamente conectada\n",
        "        x = x.view(-1, 120)\n",
        "\n",
        "        # Aplicar la primera capa completamente conectada seguida de ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Aplicar la segunda capa completamente conectada\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # No es necesario aplicar el softmax si se utiliza el \"CrossEntropyLoss\"\n",
        "        #x = F.softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mc4kjr9qKKQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, debemos instanciar el modelo"
      ],
      "metadata": {
        "id": "oasmzwMH8_65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "2kKrZVxzLtdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos probar para un salida cualquier que tipo de salida obtenemos."
      ],
      "metadata": {
        "id": "Dn_25y1f9DJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(32,1,32,32)\n",
        "\n",
        "# 'x' es un 'batch' de cuatro imagenes de 28x28x1\n",
        "y = model(x)\n",
        "\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "UY0qG9mb9M65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La dimension de los 'kernels' de nuestro modelo"
      ],
      "metadata": {
        "id": "jauWYDPI-XdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capas convolucionales"
      ],
      "metadata": {
        "id": "IbeQGrSr-x0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"conv1 shape (W): {model.conv1.weight.size()}\")\n",
        "print(f\"conv1 shape (b): {model.conv1.bias.size()}\")\n",
        "\n",
        "print(f\"conv2 shape (W): {model.conv2.weight.size()}\")\n",
        "print(f\"conv2 shape (b): {model.conv2.bias.size()}\")\n",
        "\n",
        "print(f\"conv3 shape (W): {model.conv3.weight.size()}\")\n",
        "print(f\"conv3 shape (b): {model.conv3.bias.size()}\")"
      ],
      "metadata": {
        "id": "0Ipbr4tT-dd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capas 'Full Connected'"
      ],
      "metadata": {
        "id": "1n8F_lTD-0NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"fc shape (W): {model.fc1.weight.size()}\")\n",
        "print(f\"fc1 shape (b): {model.fc1.bias.size()}\")\n",
        "\n",
        "print(f\"fc2 shape (W): {model.fc2.weight.size()}\")\n",
        "print(f\"fc2 shape (b): {model.fc2.bias.size()}\")"
      ],
      "metadata": {
        "id": "1TeIJp0aL0QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de Activación **Softmax**\n",
        "\n",
        "La función softmax es una función de activación que convierte un vector de valores arbitrarios en un vector de probabilidades, donde la suma de todas las probabilidades es igual a 1. Es especialmente útil en problemas de clasificación donde se necesita asignar probabilidades a diferentes clases (múltiples clases).\n",
        "\n",
        "Matemáticamente, la función softmax para una entrada $\\mathbf{z}=[z_1,z_2,\\cdots,z_N]$:\n",
        "\n",
        "$$y_i=\\texttt{softmax}(z_i)=\\frac{e^{z_i}}{\\sum_{k=1}^N e^{z_k}}$$\n",
        "\n",
        "donde $e$ es la base de logaritmo natural.\n",
        "\n",
        "**Aplicación de Softmax en Tareas de Clasificación:**\n",
        "\n",
        "* **Transformación a Probabilidades**: Esto es crucial para interpretar las salidas del modelo como probabilidades de pertenencia a cada clase.\n",
        "\n",
        "* **Facilita la Comparación entre Clases**: La clase con la probabilidad más alta después de aplicar softmax es la predicción del modelo.\n",
        "\n",
        "* **Compatibilidad con la Función de Pérdida**: La función de **Costo de Entropía Cruzada (Cross-Entropy)**, comúnmente utilizada en tareas de clasificación, requiere que las salidas del modelo sean probabilidades. Softmax garantiza que las salidas del modelo sean compatibles con esta función de pérdida."
      ],
      "metadata": {
        "id": "ELYBRLIQ_eoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función de Costo\n",
        "\n",
        "La función de costo o pérdida de entropía cruzada (Cross-Entropy Loss) es ampliamente utilizada en tareas de clasificación. Esta función mide la diferencia entre las distribuciones de probabilidad predichas por el modelo y las verdaderas etiquetas de clase."
      ],
      "metadata": {
        "id": "gEZhRkQrnghR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición Matemática\n",
        "\n",
        "Para un solo ejemplo de entrada con $N$ clases, la entropía cruzada se define como:\n",
        "\n",
        " $$CE=-\\frac{1}{\\mathcal{B}}\\sum_{i}^{\\mathcal{B}}t_i\\log(y_i)$$\n",
        "\n",
        "donde $\\mathcal{B}$ es el tamaño del batch, es decir la cantidad de imagenes que se está utilizando en cada iteración. Además:\n",
        "\n",
        "* $t_i$ es el valor verdadero de la $i$-ésima clase (0 o 1, en **one-hot encoding**).\n",
        "* $y_i$ es la probabilidad predicha por el modelo para la $i$-ésima clase."
      ],
      "metadata": {
        "id": "PifvhLsKlkGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CerzoUmQngHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Que es un optimizador?\n",
        "\n",
        "Un optimizador es un algoritmo que ajusta iterativamente los parámetros (pesos y biases) de un modelo de red neuronal para minimizar la función de pérdida durante el entrenamiento. El objetivo principal del optimizador es encontrar los valores de los parámetros que hacen que el modelo realice una predicción de los resultados más cercana a los valores reales en los datos de entrenamiento.\n",
        "\n",
        "**¿Cómo Funciona un Optimizador?**\n",
        "\n",
        "* **Inicialización de Parámetros**: Los parámetros del modelo se inicializan con valores aleatorios.\n",
        "\n",
        "* **Cálculo de la Pérdida**: La función de pérdida se calcula para medir cuán lejos están las predicciones del modelo de las etiquetas reales.\n",
        "\n",
        "* **Cálculo del Gradiente**: Se utiliza el algoritmo de *Backpropagation* para calcular los gradientes de la función de pérdida con respecto a cada parámetro del modelo.\n",
        "\n",
        "* **Actualización de Parámetros**: Los parámetros del modelo se **actualizan en la dirección opuesta a la del gradiente para reducir la pérdida**. La magnitud de cada actualización está controlada por la **tasa de aprendizaje** o *Learning Rate*.\n",
        "\n",
        "Este ciclo se repite durante múltiples épocas hasta que la función de pérdida se minimiza o se alcanza un criterio de parada."
      ],
      "metadata": {
        "id": "M4y1PuLDCx54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# El optimizador Adam\n",
        "\n",
        "1. $m_t\\leftarrow \\beta_1\\cdot m_{t-1}+(1-\\beta_1)\\cdot g_t$\n",
        "2. $v_t\\leftarrow \\beta_2\\cdot v_{t-1}+(1-\\beta_2)\\cdot g^2_t$\n",
        "3. $\\hat{m}_t\\leftarrow \\frac{m_t}{1-\\beta^t_1}$\n",
        "4. $\\hat{v}_t\\leftarrow \\frac{v_t}{1-\\beta^t_2}$\n",
        "5. $\\theta_t\\leftarrow \\theta_{t-1}-\\alpha\\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\epsilon}$\n",
        "\n",
        "donde:\n",
        "\n",
        "* $\\theta_t$: El parámetro del modelo en la iteración $t$.\n",
        "* $\\alpha$: La tasa de aprendizaje\n",
        "* $\\epsilon$: Es un pequeño valor constante para evitar la división por cero (típicamente $10^{-8}$).\n",
        "* $m_t$: El momento de primer orden.\n",
        "* $v_t$: El momento de segundo orden.\n",
        "* $g_t$: La gradiente en la iteración $t$.\n",
        "\n",
        "\n",
        "## Beneficios del Optimizador Adam\n",
        "\n",
        "* **Rápida Convergencia**: Adam tiende a converger más rápidamente que otros optimizadores, lo cual es particularmente útil en redes neuronales profundas y grandes conjuntos de datos.\n",
        "\n",
        "* **Robustez**: Adam es robusto frente a hiperparámetros mal ajustados, lo que lo hace más fácil de usar en comparación con otros optimizadores que requieren una cuidadosa sintonización de hiperparámetros.\n",
        "\n",
        "* **Estabilidad**: La combinación de momentos de primer y segundo orden proporciona una actualización más estable, lo que ayuda a evitar oscilaciones en el proceso de entrenamiento.\n",
        "\n",
        "* **Eficiencia Computacional**: Aunque Adam realiza cálculos adicionales en comparación con **SGD**, sigue siendo computacionalmente eficiente ."
      ],
      "metadata": {
        "id": "pRt_ttRTpYHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "_MEZFL6vMCSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento\n",
        "\n",
        "El entrenamiento nos permite ajustar los parámetros del modelo para minimizar la función de pérdida en los datos de entrenamiento.\n",
        "\n",
        "Durante el entrenamiento, el modelo aprende a mapear las entradas a las salidas correctas a través de un proceso iterativo. Se utiliza el conjunto de datos de entrenamiento para calcular el la función de pérdida, los gradientes y luego actualizar los parámetros del modelo."
      ],
      "metadata": {
        "id": "u51o14KYGIku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, valid_data, optimizer, num_epochs):\n",
        "  train_loader, valid_loader = split_train_valid_data(train_data, valid_data)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_steps = len(train_loader) # nro. de batch\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      output = model(images)\n",
        "      loss   = loss_function(output, labels)\n",
        "\n",
        "      # Limpiar gradientes\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Backpropagation: Calculo de la gradientes\n",
        "      loss.backward()\n",
        "\n",
        "      # Actualizando de los parametros\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], it: [{i+1:0>4}/{train_steps}], loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Validacion\n",
        "    model.eval()\n",
        "    valid_steps = len(valid_loader) # nro. de batch\n",
        "    valid_loss = []\n",
        "    for i, (images, labels) in enumerate(valid_loader):\n",
        "      output = model(images)\n",
        "      loss   = loss_function(output, labels)\n",
        "      valid_loss.append(loss.item())\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], valid_loss: {np.mean(valid_loss):.4f}\")\n"
      ],
      "metadata": {
        "id": "rJ38xdi5n7x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación del modelo\n",
        "\n",
        "La evualición es un paso fundamental para medir el rendimiento del modelo en datos no vistos durante el entrenamiento y ajustar hiperparámetros.\n",
        "\n",
        "El conjunto de validación se utiliza para seleccionar el mejor modelo y ajustar hiperparámetros como la tasa de aprendizaje, la regularización, y la arquitectura del modelo. **No se utiliza para entrenar el modelo**; en cambio, se evalúa periódicamente durante el entrenamiento para verificar si el modelo está mejorando y para prevenir el sobreajuste.\n"
      ],
      "metadata": {
        "id": "MW9uXTomGwoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=1\n",
        "\n",
        "train(model, train_data, valid_data, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "On1EXFe5ojeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracty(outputs, labels):\n",
        "  preds  = np.argmax(outputs.detach().numpy(), axis=1)\n",
        "  labels = labels.numpy()\n",
        "\n",
        "  acc = (preds == labels)\n",
        "\n",
        "  return np.mean(acc)\n",
        "\n",
        "def evaluacion_test_data(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  loss_it = []\n",
        "  acc_it  = []\n",
        "\n",
        "  total_steps = len(test_loader)\n",
        "\n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_function(outputs, labels)\n",
        "    acc  = get_accuracty(outputs, labels)\n",
        "\n",
        "    loss_it.append(loss.item())\n",
        "    acc_it.append(acc.item())\n",
        "\n",
        "  print('Loss={:.4f}, Accuracy={:.4f}'.format(np.mean(loss_it), np.mean(acc_it)))"
      ],
      "metadata": {
        "id": "mN5PIP_so2Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluacion_test_data(model, test_loader)"
      ],
      "metadata": {
        "id": "uZqarCcDalPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 9))\n",
        "cols, rows = 5, 5\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(test_data), size=(1,)).item()\n",
        "    image, label = test_data[sample_idx]\n",
        "\n",
        "    output = model(image.unsqueeze(0))\n",
        "\n",
        "    pred = np.argmax(output.detach().numpy(), axis=1)[0]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(pred)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image.squeeze(), cmap=\"inferno\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NQvtIWLWbIDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}