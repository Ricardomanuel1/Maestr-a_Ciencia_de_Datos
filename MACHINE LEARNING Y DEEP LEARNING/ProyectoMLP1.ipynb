{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardomanuel1/Maestria_Ciencia_de_Datos/blob/main/MACHINE%20LEARNING%20Y%20DEEP%20LEARNING/ProyectoMLP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Primer Proyecto de MLPs**\n",
        "\n",
        "- El objetivo de este ejercicio es revisar todos los conceptos vistos en clase hasta ahora, para construir una arquitectura de red neuronal completamente conectada (MLP), que tenga el mejor desempeño posible sobre una tarea dada.\n",
        "\n",
        "- La idea es que a través de la experimentación, lleguemos a construir un modelo robusto, que sirva como base para resolver otras tareas similares.\n",
        "\n",
        "- El problema a resolver es de clasificación de imágenes usando CIFAR10."
      ],
      "metadata": {
        "id": "bCWyQIVHOfbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conjunto de Datos**\n",
        "\n",
        "El conjunto de datos CIFAR10 tiene imágenes de 32x32 píxeles. Hay 50.000 imágenes de entrenamiento y 10.000 imágenes de pruebas. Cada imagen en CIFAR10 tiene asignada una de las diez clases disponibles.\n"
      ],
      "metadata": {
        "id": "PUABO_FJOgDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWH2fwPyso52",
        "outputId": "db0d188b-1d7b-4b1a-f737-7c88760c033d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "8CzmITpztpVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Etapas mínimas a realizar**"
      ],
      "metadata": {
        "id": "w1IUsNvEPnCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Separar los conjuntos de entrenamiento, validación y prueba correspondientes.\n",
        "2. Aplicar escala y normalización, si lo cree conveniente.\n",
        "3. Usar el enfoque funcional (functional API) para definir la arquitectura de la red neuronal MLP.\n",
        "4. La arquitectura debe ser profunda, con por lo menos 5 capas densas. Definir un número de neuronas para cada capa oculta, función de costo y justificar esas elecciones.\n",
        "5. Usar Callbacks: ModelCheckpoint y EarlyStopping al momento de entrenar.\n",
        "6. Mostrar el gráfico de la función de costo en tiempo de entrenamiento vs tiempo de validación, para verificar si hay overfitting.  \n",
        "6. Definir una función de activación y también un mecanismo de inicialización de pesos. Justificar esta elección.\n",
        "7. Usar el mecanismo de Batch Normalization. Justificar la elección de sus hiperparámetros.\n",
        "8. Usar un mecanismo de regularización (puede ser Dropout).\n",
        "9. Definir una función de optimización y justificar su elección.\n",
        "10. Encontrar una taza de aprendizaje adecuada usando alguna estrategia de *Learning Rate Scheduling*. Justificar la elección de sus hiperparámetros.\n",
        "11. Realizar un proceso de ajuste de hiperparámetros (los que considere convenientes), usando Keras Tuner.\n",
        "12. Reporte el resultado final en el conjunto de prueba usando la(s) métrica(s) de clasificación seleccionada(s).\n",
        "13. Definir una segunda arquitectura reutilizando todas las capas y sus pesos (a excepción de la capa de salida) haciendo una conexión *wide and deep*, de las entradas. Mejora el resultado?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rhPWuSdwPsRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Recomendaciones**\n",
        "\n",
        "- Se pueden intentar otras optimizaciones adicionales, arquitecturas y afinamientos. El objetivo es intentar mejorar cada vez más la métrica del problema en cuestión.\n",
        "\n",
        "- En la medida de lo posible, justifique las elecciones de arquitectura, hiperparámetros, etc.\n",
        "\n",
        "- Es posible, que una arquitectura más simple resuelva mejor el problema, indicar esto después de haber probado la configuración básica propuesta."
      ],
      "metadata": {
        "id": "p43NgJFPVQqV"
      }
    }
  ]
}